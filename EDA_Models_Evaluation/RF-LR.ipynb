{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b71ebe-c363-4b8f-bacc-7027b44a4f46",
   "metadata": {},
   "source": [
    "Step 1: Add More Models\n",
    "We'll use models such as:\n",
    "\n",
    "Random Forest Classifier - Handles non-linear relationships and works well for tabular data.\n",
    "\n",
    "Logistic Regression (Multinomial) - Simple linear model for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d0b30a1-a8a9-4d60-b2d3-90935198f48b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- UDI: integer (nullable = true)\n",
      " |-- Product ID: string (nullable = true)\n",
      " |-- Type: string (nullable = true)\n",
      " |-- Air temperature [K]: double (nullable = true)\n",
      " |-- Process temperature [K]: double (nullable = true)\n",
      " |-- Rotational speed [rpm]: integer (nullable = true)\n",
      " |-- Torque [Nm]: double (nullable = true)\n",
      " |-- Tool wear [min]: integer (nullable = true)\n",
      " |-- Target: integer (nullable = true)\n",
      " |-- Failure Type: string (nullable = true)\n",
      " |-- failure_type_id: double (nullable = true)\n",
      " |-- type_id: integer (nullable = true)\n",
      " |-- product_name: string (nullable = true)\n",
      " |-- product_category: string (nullable = true)\n",
      " |-- manufacturer: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- quarter: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      "\n",
      "+---+----------+----+-------------------+-----------------------+----------------------+-----------+---------------+------+------------+---------------+-------+------------+------------------+------------+----------+-------------------+-------+-----------+\n",
      "|UDI|Product ID|Type|Air temperature [K]|Process temperature [K]|Rotational speed [rpm]|Torque [Nm]|Tool wear [min]|Target|Failure Type|failure_type_id|type_id|product_name|  product_category|manufacturer|      date|          timestamp|quarter|day_of_week|\n",
      "+---+----------+----+-------------------+-----------------------+----------------------+-----------+---------------+------+------------+---------------+-------+------------+------------------+------------+----------+-------------------+-------+-----------+\n",
      "|  1|    M14860|   M|              298.1|                  308.6|                  1551|       42.8|              0|     0|  No Failure|            5.0|      1|   Monitor P|Monitoring Devices|         ABB|2024-03-11|2024-03-11 04:00:00|      1|     Monday|\n",
      "|  2|    L47181|   L|              298.2|                  308.7|                  1408|       46.3|              3|     0|  No Failure|            5.0|      2|    Device Z|   Heavy Machinery|   Honeywell|2024-03-11|2024-03-11 02:00:00|      1|     Monday|\n",
      "|  3|    L47182|   L|              298.1|                  308.5|                  1498|       49.4|              5|     0|  No Failure|            5.0|      2|   Machine A|           Sensors|          GE|2024-03-11|2024-03-11 07:00:00|      1|     Monday|\n",
      "|  4|    L47183|   L|              298.2|                  308.6|                  1433|       39.5|              7|     0|  No Failure|            5.0|      2|  Actuator Y|Monitoring Devices|       Bosch|2024-03-11|2024-03-11 17:00:00|      1|     Monday|\n",
      "|  5|    L47184|   L|              298.2|                  308.7|                  1408|       40.0|              9|     0|  No Failure|            5.0|      2|    Device Z|   Heavy Machinery|         ABB|2024-03-11|2024-03-11 20:00:00|      1|     Monday|\n",
      "+---+----------+----+-------------------+-----------------------+----------------------+-----------+---------------+------+------------+---------------+-------+------------+------------------+------------+----------+-------------------+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Total rows: 10000\n",
      "Total columns: 19\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Step 1: Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Multiclass Failure Prediction\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"C:/Users/Zahra/Desktop/ProjectBigDataAnalytics/data/predictive_maintenance_data_all_columns.csv\"  \n",
    "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Display schema and first few rows\n",
    "data.printSchema()\n",
    "data.show(5)\n",
    "\n",
    "# Count rows and columns\n",
    "print(f\"Total rows: {data.count()}\")\n",
    "print(f\"Total columns: {len(data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b0987cf-ffdc-4082-a276-7eb8d20a9273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+------------+------------------+\n",
      "|Type|Air temperature [K]|Process temperature [K]|Rotational speed [rpm]|Torque [Nm]|Tool wear [min]|Failure Type|Failure_Type_Index|\n",
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+------------+------------------+\n",
      "|   M|              298.1|                  308.6|                  1551|       42.8|              0|  No Failure|               0.0|\n",
      "|   L|              298.2|                  308.7|                  1408|       46.3|              3|  No Failure|               0.0|\n",
      "|   L|              298.1|                  308.5|                  1498|       49.4|              5|  No Failure|               0.0|\n",
      "|   L|              298.2|                  308.6|                  1433|       39.5|              7|  No Failure|               0.0|\n",
      "|   L|              298.2|                  308.7|                  1408|       40.0|              9|  No Failure|               0.0|\n",
      "+----+-------------------+-----------------------+----------------------+-----------+---------------+------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Step 2.1: Drop rows with missing values (or use .fillna() for filling missing data)\n",
    "data_cleaned = data.na.drop()\n",
    "\n",
    "# Step 2.2: Select essential features\n",
    "# Exclude irrelevant features like 'UDI', 'Manufacturer', 'Timestamp', etc.\n",
    "selected_features = ['Type', 'Air temperature [K]', 'Process temperature [K]', \n",
    "                     'Rotational speed [rpm]', 'Torque [Nm]', \n",
    "                     'Tool wear [min]', 'Failure Type']\n",
    "data_selected = data_cleaned.select(selected_features)\n",
    "\n",
    "# Step 2.3: Convert 'Failure Type' to numerical values for classification\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"Failure Type\", outputCol=\"Failure_Type_Index\")\n",
    "data_prepared = indexer.fit(data_selected).transform(data_selected)\n",
    "\n",
    "# Show prepared data\n",
    "data_prepared.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9126b82a-6e12-4809-b9d8-42835ac13e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 8079 rows\n",
      "Test set: 1921 rows\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Split the data into training and testing sets\n",
    "train_data, test_data = data_prepared.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Training set: {train_data.count()} rows\")\n",
    "print(f\"Test set: {test_data.count()} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d1653f-68c9-43c9-b26e-82bb64d08511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "# Step 4.1: Assemble features into a vector\n",
    "feature_columns = ['Air temperature [K]', 'Process temperature [K]', \n",
    "                   'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "train_data = assembler.transform(train_data)\n",
    "test_data = assembler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c466960-abe0-4d90-b3b9-7187a715b61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+----------+\n",
      "|            features|Failure_Type_Index|prediction|\n",
      "+--------------------+------------------+----------+\n",
      "|[295.6,306.1,1256...|               0.0|       0.0|\n",
      "|[295.6,306.2,1632...|               0.0|       0.0|\n",
      "|[295.7,306.2,1458...|               0.0|       0.0|\n",
      "|[296.2,307.0,1542...|               0.0|       0.0|\n",
      "|[296.4,307.5,1403...|               0.0|       0.0|\n",
      "+--------------------+------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier, LogisticRegression\n",
    "\n",
    "# Step 1.1: Random Forest Classifier\n",
    "rf = RandomForestClassifier(labelCol=\"Failure_Type_Index\", featuresCol=\"features\", numTrees=50)\n",
    "rf_model = rf.fit(train_data)\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "\n",
    "# Step 1.2: Gradient-Boosted Trees Classifier\n",
    "# gbt = GBTClassifier(labelCol=\"Failure_Type_Index\", featuresCol=\"features\", maxIter=20)\n",
    "# gbt_model = gbt.fit(train_data)\n",
    "# gbt_predictions = gbt_model.transform(test_data)\n",
    "\n",
    "# Step 1.3: Logistic Regression (Multinomial)\n",
    "lr = LogisticRegression(labelCol=\"Failure_Type_Index\", featuresCol=\"features\", maxIter=10, family=\"multinomial\")\n",
    "lr_model = lr.fit(train_data)\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Display predictions from each model (example: Random Forest)\n",
    "rf_predictions.select(\"features\", \"Failure_Type_Index\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c00831a7-0f1a-4a48-adf8-b31f8cfb2911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9672045809474232\n",
      "Precision: 0.9567811903522471\n",
      "Recall: 0.9672045809474232\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Evaluate the model\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Failure_Type_Index\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "accuracy = evaluator.evaluate(rf_predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Optional: Compute precision and recall\n",
    "precision = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(rf_predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22110652-e129-4c02-a3ab-dac52cff8c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9729307652264445\n",
      "Precision: 0.9637389628811835\n",
      "Recall: 0.9729307652264445\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Evaluate the model\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Failure_Type_Index\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "accuracy = evaluator.evaluate(lr_predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Optional: Compute precision and recall\n",
    "precision = evaluator.evaluate(lr_predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(lr_predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d49ecf73-2238-4997-ac23-4dab77943e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+-----+\n",
      "|Failure_Type_Index|prediction|count|\n",
      "+------------------+----------+-----+\n",
      "|               0.0|       0.0| 1842|\n",
      "|               0.0|       1.0|    5|\n",
      "|               0.0|       2.0|    1|\n",
      "|               1.0|       0.0|   18|\n",
      "|               1.0|       1.0|    8|\n",
      "|               2.0|       0.0|    3|\n",
      "|               2.0|       2.0|   15|\n",
      "|               2.0|       3.0|    1|\n",
      "|               3.0|       0.0|   13|\n",
      "|               3.0|       3.0|    4|\n",
      "|               4.0|       0.0|    6|\n",
      "|               5.0|       0.0|    5|\n",
      "+------------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix\n",
    "confusion_matrix = lr_predictions.select(\"Failure_Type_Index\", \"prediction\") \\\n",
    "                              .groupBy(\"Failure_Type_Index\", \"prediction\") \\\n",
    "                              .count() \\\n",
    "                              .orderBy(\"Failure_Type_Index\", \"prediction\")\n",
    "\n",
    "confusion_matrix.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7420d5fc-2be9-4064-9bc7-0f090236eea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
